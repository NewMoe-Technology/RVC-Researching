{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9c4f913-8697-4aa3-b977-5bde7f11283f",
   "metadata": {},
   "source": [
    "### RMVPE 导出测试\n",
    "RMVPE ONNX原始权重可在[此处](https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main)下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f9805b-3c81-4cd1-b251-b481cb3decfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Collecting onnxruntime-gpu\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/e0/a5/5c2287d61f359c7342e9d59d1e3dd728a982dea85f846c7af305a801c3ca/onnxruntime_gpu-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (291.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.5/291.5 MB\u001b[0m \u001b[31m502.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:10\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs (from onnxruntime-gpu)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers (from onnxruntime-gpu)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b8/25/155f9f080d5e4bc0082edfda032ea2bc2b8fab3f4d25d46c1e9dd22a1a89/flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (23.2)\n",
      "Collecting protobuf (from onnxruntime-gpu)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/a8/45/2ebbde52ad2be18d3675b6bee50e68cd73c9e0654de77d595540b5129df8/protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m820.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-gpu) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Installing collected packages: flatbuffers, protobuf, humanfriendly, coloredlogs, onnxruntime-gpu\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 onnxruntime-gpu-1.20.1 protobuf-5.29.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a349e397-da4e-4f46-8f75-50a9c13ad61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cefe9869-d63f-44ee-8c5b-c244cdd3acdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2025-02-17 16:34:43.712099212 [E:onnxruntime:Default, provider_bridge_ort.cc:1862 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1539 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcudnn.so.9: cannot open shared object file: No such file or directory\n",
      "\u001b[m\n",
      "\u001b[0;93m2025-02-17 16:34:43.712128197 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:993 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# 读取ONNX模型\n",
    "model = ort.InferenceSession(\"./rmvpe.onnx\",providers=['CUDAExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3233848f-978a-4daa-86d1-1bdb72dd7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchaudio.transforms import MelScale\n",
    "\n",
    "class MelSpectrogram(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        is_half,\n",
    "        n_mel_channels,\n",
    "        sampling_rate,\n",
    "        win_length,\n",
    "        hop_length,\n",
    "        n_fft=None,\n",
    "        mel_fmin=0,\n",
    "        mel_fmax=None,\n",
    "        clamp=1e-5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        n_fft = win_length if n_fft is None else n_fft\n",
    "        # Initialize MelScale for computing mel basis\n",
    "        self.mel_scale = MelScale(\n",
    "            n_mels=n_mel_channels,\n",
    "            sample_rate=sampling_rate,\n",
    "            f_min=mel_fmin,\n",
    "            f_max=mel_fmax,\n",
    "            n_stft=n_fft // 2 + 1,\n",
    "        )\n",
    "        self.n_fft = win_length if n_fft is None else n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.win_length = win_length\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.n_mel_channels = n_mel_channels\n",
    "        self.clamp = clamp\n",
    "        self.is_half = is_half\n",
    "        self.hann_window = {}\n",
    "\n",
    "    def forward(self, audio, keyshift=0, speed=1, center=True):\n",
    "        factor = 2 ** (keyshift / 12)\n",
    "        n_fft_new = int(torch.round(torch.tensor(self.n_fft * factor)).item())\n",
    "        win_length_new = int(torch.round(torch.tensor(self.win_length * factor)).item())\n",
    "        hop_length_new = int(torch.round(torch.tensor(self.hop_length * speed)).item())\n",
    "\n",
    "        keyshift_key = str(keyshift) + \"_\" + str(audio.device)\n",
    "\n",
    "        # Ensure hann_window is always initialized\n",
    "        if keyshift_key not in self.hann_window:\n",
    "            self.hann_window[keyshift_key] = torch.hann_window(win_length_new).to(audio.device)\n",
    "\n",
    "        # Compute STFT with return_complex=False\n",
    "        stft_real, stft_imag = torch.stft(\n",
    "            audio,\n",
    "            n_fft=n_fft_new,\n",
    "            hop_length=hop_length_new,\n",
    "            win_length=win_length_new,\n",
    "            window=self.hann_window[keyshift_key],\n",
    "            center=center,\n",
    "            return_complex=False,  # Return real and imaginary parts separately\n",
    "        ).unbind(-1)\n",
    "\n",
    "        # Compute magnitude spectrogram manually\n",
    "        magnitude = torch.sqrt(stft_real.pow(2) + stft_imag.pow(2))\n",
    "\n",
    "        # Handle keyshift resizing\n",
    "        if keyshift != 0:\n",
    "            size = self.n_fft // 2 + 1\n",
    "            resize = magnitude.size(1)\n",
    "            if resize < size:\n",
    "                magnitude = F.pad(magnitude, (0, 0, 0, size - resize))\n",
    "            magnitude = magnitude[:, :size, :] * self.win_length / win_length_new\n",
    "\n",
    "        # Apply MelScale transformation\n",
    "        mel_output = self.mel_scale(magnitude)\n",
    "\n",
    "        # Clamp and log\n",
    "        if self.is_half:\n",
    "            mel_output = mel_output.half()\n",
    "        log_mel_spec = torch.log(torch.clamp(mel_output, min=self.clamp))\n",
    "\n",
    "        return log_mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b83fc953-d427-4629-b91d-8e5677a46de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRMVPE(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model: ort.InferenceSession,\n",
    "            is_half: bool = False,\n",
    "            device: str = \"cuda\",\n",
    "        ):\n",
    "        super(MyRMVPE, self).__init__()\n",
    "        self.model = model\n",
    "        self.is_half = is_half\n",
    "        self.device = torch.device(device)  # 显式定义设备\n",
    "        if is_half:\n",
    "            self.model = self.model.half()\n",
    "        self.mel_extractor = MelSpectrogram(\n",
    "            is_half, 128, 16000, 1024, 160, None, 30, 8000\n",
    "        ).to(self.device)\n",
    "        self.cents_mapping = 20 * torch.arange(360, device=self.device) + 1997.3794084376191\n",
    "        self.cents_mapping = torch.nn.functional.pad(\n",
    "            self.cents_mapping.unsqueeze(0), (4, 4), mode=\"constant\", value=0\n",
    "        ).to(self.device)\n",
    "\n",
    "    def mel2hiden(self, mel):\n",
    "        n_frames = mel.shape[-1]\n",
    "        n_pad = 32 * ((n_frames - 1) // 32 + 1) - n_frames\n",
    "        if n_pad > 0:\n",
    "            mel = torch.nn.functional.pad(mel, (0, n_pad), mode=\"constant\")\n",
    "        mel = mel.half() if self.is_half else mel.float()\n",
    "        mel = mel.to(self.device)  # 确保mel在正确设备上\n",
    "        hidden = torch.from_numpy(\n",
    "            self.model.run(\n",
    "                [\"output\"],{\"input\":mel.cpu().numpy()}\n",
    "            )[0]\n",
    "        ).to(self.device)\n",
    "        return hidden[:, :n_frames].to(self.device)\n",
    "\n",
    "    def to_local_average_cents(self, salience, thred=0.05):\n",
    "        center = torch.argmax(salience, dim=-1)  # [batch]\n",
    "        salience = F.pad(salience, (4, 4), \"constant\", 0)  # [batch, 360 + 8]\n",
    "        center += 4\n",
    "\n",
    "        # 确保 clamp 的 max 参数在同一设备上\n",
    "        max_value = torch.tensor(salience.shape[-1] - 1, device=self.device)\n",
    "        starts = (center - 4).clamp(min=0)                     # 防止负数索引\n",
    "        ends = (center + 5).clamp(max=max_value)               # 防止越界\n",
    "\n",
    "        batch_size = salience.shape[0]\n",
    "        indices = torch.arange(salience.shape[-1], device=self.device)  # [368]\n",
    "        indices = indices.view(1, -1).expand(batch_size, -1)  # [batch, 368]\n",
    "\n",
    "        mask = (indices >= starts.unsqueeze(-1)) & (indices < ends.unsqueeze(-1))\n",
    "\n",
    "        window_salience = salience * mask.float()  # [batch, 368]\n",
    "        window_cents = self.cents_mapping.expand(batch_size, -1) * mask.float()  # [batch, 368]\n",
    "\n",
    "        product_sum = torch.sum(window_salience * window_cents, dim=-1)  # [batch]\n",
    "        weight_sum = torch.sum(window_salience, dim=-1)                  # [batch]\n",
    "        weight_sum = torch.where(weight_sum == 0, torch.tensor(1e-6, device=self.device), weight_sum)\n",
    "\n",
    "        devided = product_sum / weight_sum  # [batch]\n",
    "\n",
    "        max_values = torch.max(salience, dim=-1).values  # [batch]\n",
    "        devided[max_values <= thred] = 0\n",
    "\n",
    "        return devided\n",
    "\n",
    "    def decode(self, hidden, thred=0.03):\n",
    "        cents_pred = self.to_local_average_cents(hidden, thred=thred)\n",
    "        f0 = 10 * (2 ** (cents_pred / 1200))\n",
    "        f0[f0 == 10] = 0\n",
    "        return f0\n",
    "\n",
    "    def forward(self, audio, thred=0.03):\n",
    "        audio = audio.to(self.device)  # 确保输入音频在正确设备上\n",
    "        mel = self.mel_extractor(audio.float().unsqueeze(0), center=True).to(self.device)\n",
    "        hidden = self.mel2hiden(mel)\n",
    "        f0 = self.decode(hidden, thred=thred).squeeze(0)\n",
    "        return f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cabb7c6c-c61a-4afe-a8f3-a0118d29d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41975bf0-3925-4f58-ac00-9e105777b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load(\"./x.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71af4ba6-b235-485f-9a40-f613fd8d15fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2800,  0.1129, -0.0576,  ...,  0.2808,  0.0731, -0.1258],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33192023-61e2-4584-99b8-46f46763457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([266.6708, 263.3647, 260.0292,  ..., 343.5811, 344.1398, 343.8999],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 执行推理\n",
    "rmvpe = MyRMVPE(model)\n",
    "rmvpe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27d4f8db-8f83-403e-9603-89cd9275f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Collecting onnx\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/b1/2f/91092557ed478e323a2b4471e2081fdf88d1dd52ae988ceaf7db4e4506ff/onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m802.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.3)\n",
      "Installing collected packages: onnx\n",
      "Successfully installed onnx-1.17.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd9cb9a8-fedf-4037-a85e-38e5dc3fad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5710/4006520857.py:39: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  n_fft_new = int(torch.round(torch.tensor(self.n_fft * factor)).item())\n",
      "/tmp/ipykernel_5710/4006520857.py:39: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  n_fft_new = int(torch.round(torch.tensor(self.n_fft * factor)).item())\n",
      "/tmp/ipykernel_5710/4006520857.py:40: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  win_length_new = int(torch.round(torch.tensor(self.win_length * factor)).item())\n",
      "/tmp/ipykernel_5710/4006520857.py:40: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  win_length_new = int(torch.round(torch.tensor(self.win_length * factor)).item())\n",
      "/tmp/ipykernel_5710/4006520857.py:41: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  hop_length_new = int(torch.round(torch.tensor(self.hop_length * speed)).item())\n",
      "/tmp/ipykernel_5710/4006520857.py:41: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  hop_length_new = int(torch.round(torch.tensor(self.hop_length * speed)).item())\n",
      "/tmp/ipykernel_5710/1500417209.py:25: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if n_pad > 0:\n",
      "/tmp/ipykernel_5710/1500417209.py:31: TracerWarning: Converting a tensor to a NumPy array might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  [\"output\"],{\"input\":mel.cpu().numpy()}\n",
      "/tmp/ipykernel_5710/1500417209.py:29: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  hidden = torch.from_numpy(\n",
      "/tmp/ipykernel_5710/1500417209.py:42: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  max_value = torch.tensor(salience.shape[-1] - 1, device=self.device)\n",
      "/tmp/ipykernel_5710/1500417209.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  max_value = torch.tensor(salience.shape[-1] - 1, device=self.device)\n",
      "/tmp/ipykernel_5710/1500417209.py:57: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  weight_sum = torch.where(weight_sum == 0, torch.tensor(1e-6, device=self.device), weight_sum)\n"
     ]
    }
   ],
   "source": [
    "# 执行导出\n",
    "torch.onnx.export(\n",
    "    rmvpe.cuda(),\n",
    "    x.cuda(),\n",
    "    \"rmvpe_pipeline.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"f0\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"seq\"},\n",
    "        \"f0\": {0: \"seq\"},\n",
    "    },\n",
    "    opset_version=17,\n",
    "    do_constant_folding=True,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5d4f582-b0b8-47e3-92f1-2b77ca17996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2025-02-17 16:43:21.030760768 [E:onnxruntime:Default, provider_bridge_ort.cc:1862 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1539 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcudnn.so.9: cannot open shared object file: No such file or directory\n",
      "\u001b[m\n",
      "\u001b[0;93m2025-02-17 16:43:21.030793651 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:993 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# 读取rmvpe_pipeline.onnx\n",
    "\n",
    "model = ort.InferenceSession(\"./rmvpe_pipeline.onnx\",providers=['CUDAExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bcbdfef-0474-49ec-b698-2ab99b7da47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5138a626-1368-452f-bfb4-0bfed32d5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.run(\n",
    "    [\"f0\"],\n",
    "    {\"input\":x,'thred':[0.03]}\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b2a4fa6-d197-4374-85ef-c428b4494356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([266.6709 , 263.36465, 260.02917, ..., 343.5814 , 344.13977,\n",
       "       343.89987], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ba565c-ec11-4e27-940c-9c6813b3cd60",
   "metadata": {},
   "source": [
    "以下代码将在我的通勤电脑（无GPU）上运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41283b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8  Intel(R) Core(TM) Ultra 7 258V\n"
     ]
    }
   ],
   "source": [
    "# 打印CPU型号\n",
    "!cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "477ec009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec963874",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ort.InferenceSession(\"./rmvpe_pipeline.onnx\",providers=['CPUExecutionProvider'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed4716ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(\"./x.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c69fb4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infernce on cpu cost 0.2364s\n"
     ]
    }
   ],
   "source": [
    "# 执行推理\n",
    "start = perf_counter()\n",
    "pred = model.run(\n",
    "    [\"f0\"],\n",
    "    {\"input\":x,'thred':[0.03]}\n",
    ")[0]\n",
    "end = perf_counter()\n",
    "print(f\"Infernce on cpu cost {end-start:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5fd8589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([266.6709 , 263.36465, 260.02917, ..., 343.5814 , 344.13977,\n",
       "       343.89987], shape=(7383,), dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225ca05",
   "metadata": {},
   "source": [
    "这波，这波我只能说微软有挂！344MB的权重被压缩成10MB不说，推理速度在CPU上能这么快？？？？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
